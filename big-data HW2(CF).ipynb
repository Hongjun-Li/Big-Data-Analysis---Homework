{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86127c7e",
   "metadata": {},
   "source": [
    "## 数据预处理\n",
    "\n",
    "+ 导入数据，将txt转化为csv的dataframe\n",
    "+ 将用户从0开始编号\n",
    "+ 通过数据透视函数构建 用户*电影 矩阵\n",
    "+ 测试集缺失部分电影，将其补全为10000 * 10000的矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc816717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "film_id  1      2      3      4      5      6      7      8      9      10     \\\n",
      "id                                                                              \n",
      "0          1.0    NaN    2.0    1.0    1.0    1.0    2.0    1.0    NaN    1.0   \n",
      "1          1.0    NaN    2.0    NaN    1.0    2.0    1.0    NaN    NaN    NaN   \n",
      "2          NaN    1.0    NaN    1.0    NaN    1.0    NaN    1.0    NaN    1.0   \n",
      "3          5.0    NaN    NaN    3.0    5.0    4.0    3.0    4.0    3.0    4.0   \n",
      "4          5.0    NaN    4.0    3.0    5.0    4.0    3.0    NaN    NaN    3.0   \n",
      "\n",
      "film_id  ...  9991   9992   9993   9994   9995   9996   9997   9998   9999   \\\n",
      "id       ...                                                                  \n",
      "0        ...    2.0    1.0    NaN    1.0    1.0    2.0    1.0    1.0    1.0   \n",
      "1        ...    NaN    1.0    1.0    1.0    NaN    2.0    1.0    1.0    2.0   \n",
      "2        ...    1.0    1.0    NaN    NaN    NaN    1.0    1.0    1.0    1.0   \n",
      "3        ...    5.0    3.0    NaN    4.0    5.0    5.0    5.0    4.0    NaN   \n",
      "4        ...    5.0    NaN    5.0    4.0    4.0    5.0    4.0    4.0    NaN   \n",
      "\n",
      "film_id  10000  \n",
      "id              \n",
      "0          2.0  \n",
      "1          1.0  \n",
      "2          1.0  \n",
      "3          5.0  \n",
      "4          4.0  \n",
      "\n",
      "[5 rows x 10000 columns]\n",
      "film_id  1      2      3      4      5      6      7      8      9      10     \\\n",
      "id                                                                              \n",
      "0          NaN    1.0    NaN    NaN    NaN    NaN    NaN    NaN    1.0    NaN   \n",
      "1          NaN    1.0    NaN    2.0    NaN    NaN    NaN    1.0    1.0    2.0   \n",
      "2          1.0    NaN    1.0    NaN    1.0    NaN    1.0    NaN    NaN    NaN   \n",
      "3          NaN    4.0    5.0    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
      "4          NaN    4.0    NaN    NaN    NaN    NaN    NaN    3.0    NaN    NaN   \n",
      "\n",
      "film_id  ...  9991   9992   9993   9994   9995   9996   9997   9998   9999   \\\n",
      "id       ...                                                                  \n",
      "0        ...    NaN    NaN    1.0    NaN    NaN    NaN    NaN    NaN    NaN   \n",
      "1        ...    1.0    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
      "2        ...    NaN    NaN    1.0    1.0    NaN    NaN    NaN    NaN    NaN   \n",
      "3        ...    NaN    NaN    4.0    NaN    NaN    NaN    NaN    NaN    3.0   \n",
      "4        ...    NaN    3.0    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
      "\n",
      "film_id  10000  \n",
      "id              \n",
      "0          NaN  \n",
      "1          NaN  \n",
      "2          NaN  \n",
      "3          NaN  \n",
      "4          NaN  \n",
      "\n",
      "[5 rows x 10000 columns]\n"
     ]
    }
   ],
   "source": [
    "# 导入包\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 导入数据\n",
    "user = pd.read_csv(\"users.txt\", names = ['userid'])\n",
    "netflix_train = pd.read_csv(\"netflix_train.txt\", sep = ' ', names = ['user_id', 'film_id', 'rating', 'date'])\n",
    "netflix_test = pd.read_csv(\"netflix_test.txt\", sep = ' ', names = ['user_id', 'film_id', 'rating', 'date'])\n",
    "\n",
    "# 在user的df中建立新的一列\n",
    "user['id'] = range(len(user))\n",
    "netflix_train = netflix_train.merge(user, left_on='user_id', right_on='userid')\n",
    "netflix_test = netflix_test.merge(user, left_on='user_id', right_on='userid')\n",
    "\n",
    "X_train = netflix_train.pivot(index='id', columns='film_id', values='rating')\n",
    "X_test = netflix_test.pivot(index='id', columns='film_id', values='rating')\n",
    "\n",
    "# 将测试集补全为10000 * 10000的矩阵\n",
    "for i in range(1, 10001):\n",
    "    if i not in X_test.columns:\n",
    "        X_test[i] = np.nan\n",
    "X_test = X_test.sort_index(axis=1)\n",
    "\n",
    "\n",
    "print(X_train.head())  # head() 默认是前5行数据\n",
    "print(X_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2bd1b1a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.013374013560779\n"
     ]
    }
   ],
   "source": [
    "# Collaborate Filtering\n",
    "# Compute the overall mean and mean by row and column\n",
    "mu = np.mean(np.mean(X_train))\n",
    "bx = np.array(np.mean(X_train, axis=1) - mu)\n",
    "by = np.array(np.mean(X_train, axis=0) - mu)\n",
    "\n",
    "# Compute the similarity matrix\n",
    "X = X_train.sub(bx+mu, axis=0)   # Demean\n",
    "X = X.div(np.sqrt(np.sum(np.square(X), axis=1)), axis=0)\n",
    "\n",
    "# fill the 0\n",
    "X.fillna(0, inplace=True)\n",
    "similarity_matrix = np.dot(X, X.T)\n",
    "\n",
    "# Compute the point matrix using CF\n",
    "X_train = np.array(X_train.fillna(0))\n",
    "for i in range(X_train.shape[0]):\n",
    "    indexs = np.argsort(similarity_matrix[i, :])[::-1]\n",
    "    for j in range(X_train.shape[1]):\n",
    "        if X_train[i, j] == 0:\n",
    "            sum = 0\n",
    "            num = 0\n",
    "            simi = 0\n",
    "            k = 0\n",
    "            while num < 3 & k < X_train.shape[1]:    # top 3\n",
    "                if X_train[indexs[k], j] > 0:\n",
    "                    sum = sum + similarity_matrix[i, indexs[k]] * (X_train[indexs[k], j] - mu - bx[indexs[k]] - by[j])\n",
    "                    simi = simi + similarity_matrix[i, indexs[k]]\n",
    "                    k = k+1\n",
    "                    num = num + 1\n",
    "                else:\n",
    "                    k = k+1\n",
    "            if simi != 0:\n",
    "                X_train[i, j] = mu + bx[i] + by[j] + sum/simi\n",
    "            else:\n",
    "                X_train[i, j] = mu + bx[i] + by[j]\n",
    "        else:\n",
    "            continue\n",
    "            \n",
    "# Compute RMSE for the algorithm\n",
    "sum = 0\n",
    "for index, rows in netflix_test.iterrows():\n",
    "    sum = sum + np.square(X_train[rows['id'], rows['film_id']-1] - rows['rating'])\n",
    "\n",
    "RMSE = np.sqrt(sum/netflix_test.shape[0])\n",
    "print(RMSE)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "49418117e3467ad040f328a538709f0a31be17b9d7cca48f864682de9e3fed76"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
